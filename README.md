# Machine Learning & Deep Learning - Basics using Scikit-Learn and TensorFlow
A collection of jupyter notebooks for Basics of Machine Learning & Deep Learning with Python 
<br><br>
Quick Links: <br>
-[Data-Precessing using Python](https://github.com/abhimanyus1997/ML-Basics/blob/main/01-Data%20Preprocessing.ipynb)

-[Pandas Basics](https://github.com/abhimanyus1997/ML-Basics/blob/main/misc-notebooks/Pandas%20-%20Basics.ipynb)

-[OpenCV Basics to Advanced](https://github.com/abhimanyus1997/ML-Basics/blob/main/misc-notebooks/opencv/01%20Basic%20OpenCV.ipynb)  
  
-Supervised Learning:
  - [Regression](https://github.com/abhimanyus1997/ML-Basics/blob/main/02-Regression.ipynb):
    - Linear Regression 
    - Polynomial Regression
    - Support Vector Regression (SVR)
    - Decision Tree Regression
    - Random Forest Regression
    - Gradient Boosting Regression (e.g., XGBoost, LightGBM)
    - Neural Network Regression

  - Classification:
    - Logistic Regression
    - Naive Bayes
    - Decision Tree Classification
    - Random Forest Classification
    - Support Vector Machines (SVM)
    - K-Nearest Neighbors (KNN)
    - Gradient Boosting Classification (e.g., XGBoost, LightGBM)
    - Neural Network Classification

-Unsupervised Learning:
  - [Clustering](https://github.com/abhimanyus1997/ML-Basics/blob/main/03-Unsupervised-Clustering.ipynb):
    - K-Means Clustering
    - Hierarchical Clustering
    - DBSCAN (Density-Based Spatial Clustering of Applications with Noise)
    - Gaussian Mixture Models (GMM)

  - Dimensionality Reduction:
    - Principal Component Analysis (PCA)
    - Linear Discriminant Analysis (LDA)
    - t-SNE (t-Distributed Stochastic Neighbor Embedding)
    - Independent Component Analysis (ICA)

  - Anomaly Detection:
    - One-Class SVM
    - Isolation Forest
    - Local Outlier Factor (LOF)

-Reinforcement Learning:
  - Q-Learning
  - Deep Q-Networks (DQN)
  - Policy Gradient Methods
  - Actor-Critic Methods
  - Monte Carlo Tree Search (MCTS)

-Semisupervised Learning:
  - Self-Training
  - Co-Training
  - Generative Models (e.g., Generative Adversarial Networks - GANs)

-Transfer Learning:
  - Pretrained models (e.g., ImageNet pretrained models for image classification)
  - Fine-tuning

-Ensemble Methods:
  - Bagging (e.g., Random Forests)
  - Boosting (e.g., AdaBoost, Gradient Boosting)
  - Stacking
  - Voting

-[Deep Learning](https://github.com/abhimanyus1997/ML-Basics/tree/main/deeplearning):
  - [Artificial Neural Networks (ANN)](https://github.com/abhimanyus1997/ML-Basics/blob/main/deeplearning/02-ANN.ipynb)
  - [Convolutional Neural Networks (CNN)](https://github.com/abhimanyus1997/ML-Basics/blob/main/deeplearning/03-CNN.ipynb)
  - [Recurrent Neural Networks (RNN)](https://github.com/abhimanyus1997/ML-Basics/blob/main/deeplearning/04-RNN.ipynb)
  - Long Short-Term Memory (LSTM)
  - Gated Recurrent Unit (GRU)
  - Transformers
  - Autoencoders
  - Generative Adversarial Networks (GANs)
