{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of OpenCV and Computer Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy Version: 1.21.5\n",
      "OpenCV Version: 4.6.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "print(\"Numpy Version:\",np.__version__)\n",
    "print(\"OpenCV Version:\",cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = cv2.imread(\"../../datasets/images/mypaint.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays image in a frame titled \"My Painting\"\n",
    "cv2.imshow(\"My Painting\", input)\n",
    "\n",
    "# Opens Frame for 2000ms = 2seconds\n",
    "cv2.waitKey(2000)\n",
    "\n",
    "# Closes all Windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Capturing Using OpenCV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Open the default camera (index 0)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "# Get the width and height of the captured frames\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Start an infinite loop to continuously capture frames\n",
    "while True:\n",
    "    # Read the current frame from the camera\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Show the grayscale frame\n",
    "    # cv2.imshow('gray frame', gray)\n",
    "    \n",
    "    # Show the frame in color (BGR)\n",
    "    cv2.imshow('bgr frame', frame)\n",
    "\n",
    "    # If the 'q' key is pressed, break the loop and exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and destroy all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Summary\n",
    "\n",
    "1. Import the cv2 module, which provides computer vision functions and video capturing capabilities.\n",
    "  \n",
    "1. Open the default camera (index 0) using ``cv2.VideoCapture(0)``.\n",
    "  \n",
    "1. Check if the camera was opened successfully using ``cap.isOpened()``. If it failed to open, print an error message and exit the program.\n",
    "  \n",
    "1. Retrieve the width and height of the captured frames using ``cap.get(cv2.CAP_PROP_FRAME_WIDTH)`` and ``cap.get(cv2.CAP_PROP_FRAME_HEIGHT)`` respectively.\n",
    "  \n",
    "1. Enter an infinite loop to continuously capture frames from the camera.\n",
    "  \n",
    "1. Read the current frame from the camera using ``cap.read()``. The ``ret`` variable indicates if the frame was read successfully, and the ``frame`` variable holds the actual frame data.\n",
    "  \n",
    "1. Convert the frame to grayscale using ``cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)``.\n",
    "  \n",
    "1. Show the grayscale frame using ``cv2.imshow('gray frame', gray)``. (This line is currently commented out.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\projects\\\\ML-Basics\\\\misc-notebooks\\\\opencv'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Open the video source\n",
    "cap = cv2.VideoCapture(0)  # Replace 0 with the appropriate video source (e.g., file path or camera index)\n",
    "\n",
    "# Get the video source properties\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Create the VideoWriter object\n",
    "writer = cv2.VideoWriter(\"saved/capturedGray.mp4\", cv2.VideoWriter_fourcc(*'X264'), 30, (width, height))\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video source\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Display the grayscale frame\n",
    "    cv2.imshow('Gray Frame', gray)\n",
    "\n",
    "    # Write the grayscale frame to the output video file\n",
    "    writer.write(gray)\n",
    "\n",
    "    # Check if the 'q' key is pressed to terminate the program\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture and VideoWriter objects\n",
    "cap.release()\n",
    "writer.release()\n",
    "\n",
    "# Close all OpenCV windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FourCC is a 4-byte code used to specify the video codec. The list of available codes can be found in fourcc.org. It is platform dependent. The following codecs work fine for me.\n",
    "  \n",
    "* In Fedora: DIVX, XVID, MJPG, X264, WMV1, WMV2. (XVID is more preferable. MJPG results in high size video. X264 gives very small size video)\n",
    "* In Windows: DIVX (More to be tested and added)\n",
    "* In OSX: MJPG (.mp4), DIVX (.avi), X264 (.mkv).\n",
    "FourCC code is passed as `cv.VideoWriter_fourcc('M','J','P','G')or cv.VideoWriter_fourcc(*'MJPG')` for MJPG."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Summary: \n",
    "\n",
    "This line creates a VideoWriter object named writer. It takes three parameters:\n",
    "\n",
    "1. The first parameter is the output filename, specified as \"saved/capturedGray.mp4\". You can change the path and filename according to your requirements.\n",
    "1. The second parameter is the four-character code representing the codec used for video compression. In this case, ``cv2.VideoWriter_fourcc(*'X264')`` specifies the H.264 video codec. You can use different codecs based on your needs.\n",
    "1. The third parameter is the number of frames per second (FPS) for the output video. In this example, it is set to 30, but you can adjust it as per your requirements.\n",
    "After creating the VideoWriter object, you can use it to write frames to the video file by calling the ``write()`` method. For each frame, you need to convert it to grayscale before writing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Video File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "# Create a VideoCapture object and open the video file\n",
    "cap = cv2.VideoCapture('saved/capturedGray.mp4')\n",
    "fps = 30\n",
    "\n",
    "# Check if the video file was successfully opened\n",
    "if cap.isOpened() == False:\n",
    "    print('ERROR: File not found or Wrong Codec')\n",
    "\n",
    "# Loop until the VideoCapture object is open\n",
    "while cap.isOpened():\n",
    "    # Read the next frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # If a frame was successfully read\n",
    "    if ret == True:\n",
    "        # Delay to achieve the desired frame rate\n",
    "        time.sleep(1/fps)\n",
    "\n",
    "        # Display the frame in a window named 'Preview Frame'\n",
    "        cv2.imshow('Preview Frame', frame)\n",
    "\n",
    "        # Check if the user pressed the 'q' key to quit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        # Break the loop if no frame was read (end of the video)\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture object\n",
    "cap.release()\n",
    "\n",
    "# Close all OpenCV windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing over Video"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drawing Rectangle over Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Initialize video capture from the default camera (index 0)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Get the width and height of the captured video frames\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Calculate the coordinates and dimensions of the rectangle\n",
    "x = width // 2  # X-coordinate of the top left corner\n",
    "y = height // 2  # Y-coordinate of the top left corner\n",
    "w = width // 4  # Width of the rectangle\n",
    "h = height // 4  # Height of the rectangle\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video capture\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Draw a rectangle on the frame using the specified coordinates, color, and thickness\n",
    "    cv2.rectangle(frame, (x, y), (x+w, y+h), color=(0, 0, 255), thickness=4)\n",
    "\n",
    "    # Display the frame in a window named 'myframe'\n",
    "    cv2.imshow('myframe', frame)\n",
    "\n",
    "    # If the 'q' key is pressed, break the loop and exit the program\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drawing Interactively on Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "## CALLBACK FUNCTION RECTANGLE\n",
    "def draw_rectangle(event, x, y, flags, param):\n",
    "    global pt1, pt2, topLeft_clicked, botRight_clicked\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # RESET THE RECTANGLE & CHECK IF THE RECTANGLE IS ALREADY THERE\n",
    "        if topLeft_clicked and botRight_clicked:\n",
    "            pt1 = (0, 0)\n",
    "            pt2 = (0, 0)\n",
    "            topLeft_clicked = False\n",
    "            botRight_clicked = False\n",
    "\n",
    "        if not topLeft_clicked:\n",
    "            pt1 = (x, y)\n",
    "            topLeft_clicked = True\n",
    "        elif not botRight_clicked:\n",
    "            pt2 = (x, y)\n",
    "            botRight_clicked = True\n",
    "\n",
    "## GLOBAL VARIABLES\n",
    "pt1 = (0, 0)\n",
    "pt2 = (0, 0)\n",
    "topLeft_clicked = False\n",
    "botRight_clicked = False\n",
    "\n",
    "## CONNECT TO CALLBACK\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create a window named 'Test'\n",
    "cv2.namedWindow('Test')\n",
    "\n",
    "# Set the 'draw_rectangle' function as the mouse callback for the 'Test' window\n",
    "cv2.setMouseCallback('Test', draw_rectangle)\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video capture\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    ## DRAWING ON THE FRAME BASED ON THE GLOBAL VARIABLES\n",
    "    if topLeft_clicked:\n",
    "        # Draw a circle at the top left corner (pt1) with a radius of 5 and red color\n",
    "        cv2.circle(frame, center=pt1, radius=5, color=(0, 0, 255), thickness=-1)\n",
    "\n",
    "    if topLeft_clicked and botRight_clicked:\n",
    "        # Draw a rectangle using the top left corner (pt1) and bottom right corner (pt2)\n",
    "        # with green color and line thickness of 3\n",
    "        cv2.rectangle(frame, pt1, pt2, (0, 255, 0), 3)\n",
    "\n",
    "    # Display the frame in the 'Test' window\n",
    "    cv2.imshow('Test', frame)\n",
    "\n",
    "    # If the 'q' key is pressed, break the loop and exit the program\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using CascadeClassifier of OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the pre-trained face cascade classifier\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Open the default camera (index 0)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "# Get the width and height of the captured frames\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Start an infinite loop to continuously capture frames\n",
    "while True:\n",
    "    # Read the current frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # If frame is not read correctly, break the loop\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Perform face detection\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Draw bounding boxes around detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    # Show the frame with detected faces\n",
    "    cv2.imshow('Face Detection', frame)\n",
    "\n",
    "    # If the 'q' key is pressed, break the loop and exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and destroy all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using DNN module for face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "\n",
    "# Download the pre-trained model files\n",
    "model_url = 'https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt'\n",
    "weights_url = 'https://github.com/opencv/opencv_3rdparty/raw/dnn_samples_face_detector_20180205_fp16/res10_300x300_ssd_iter_140000_fp16.caffemodel'\n",
    "\n",
    "model_path = 'deploy.prototxt'\n",
    "weights_path = 'res10_300x300_ssd_iter_140000_fp16.caffemodel'\n",
    "\n",
    "urllib.request.urlretrieve(model_url, model_path)\n",
    "urllib.request.urlretrieve(weights_url, weights_path)\n",
    "\n",
    "# Load the pre-trained face detection model\n",
    "net = cv2.dnn.readNetFromCaffe(model_path, weights_path)\n",
    "\n",
    "# Open the default camera (index 0)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "# Get the width and height of the captured frames\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Start an infinite loop to continuously capture frames\n",
    "while True:\n",
    "    # Read the current frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # If frame is not read correctly, break the loop\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    # Create a blob from the frame and perform face detection\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    # Iterate over the detections and draw bounding boxes around faces\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.5:\n",
    "            box = detections[0, 0, i, 3:7] * np.array([width, height, width, height])\n",
    "            (startX, startY, endX, endY) = box.astype(int)\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "\n",
    "    # Show the frame with detected faces\n",
    "    cv2.imshow('Face Detection', frame)\n",
    "\n",
    "    # If the 'q' key is pressed, break the loop and exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and destroy all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
