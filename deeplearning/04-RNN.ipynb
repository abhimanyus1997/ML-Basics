{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25-11-2021</td>\n",
       "      <td>4271.394531</td>\n",
       "      <td>4550.518066</td>\n",
       "      <td>4249.774414</td>\n",
       "      <td>4274.743164</td>\n",
       "      <td>4274.743164</td>\n",
       "      <td>1.870536e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26-11-2021</td>\n",
       "      <td>4522.208984</td>\n",
       "      <td>4550.842285</td>\n",
       "      <td>3933.506592</td>\n",
       "      <td>4030.908936</td>\n",
       "      <td>4030.908936</td>\n",
       "      <td>2.628180e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27-11-2021</td>\n",
       "      <td>4042.999023</td>\n",
       "      <td>4187.684082</td>\n",
       "      <td>4033.513916</td>\n",
       "      <td>4096.912109</td>\n",
       "      <td>4096.912109</td>\n",
       "      <td>1.651569e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28-11-2021</td>\n",
       "      <td>4101.648926</td>\n",
       "      <td>4297.916504</td>\n",
       "      <td>3989.969971</td>\n",
       "      <td>4294.453613</td>\n",
       "      <td>4294.453613</td>\n",
       "      <td>1.595313e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29-11-2021</td>\n",
       "      <td>4296.946777</td>\n",
       "      <td>4460.848633</td>\n",
       "      <td>4284.504883</td>\n",
       "      <td>4445.104980</td>\n",
       "      <td>4445.104980</td>\n",
       "      <td>1.908648e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>366 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date         Open         High          Low        Close  \\\n",
       "0    25-11-2021  4271.394531  4550.518066  4249.774414  4274.743164   \n",
       "1    26-11-2021  4522.208984  4550.842285  3933.506592  4030.908936   \n",
       "2    27-11-2021  4042.999023  4187.684082  4033.513916  4096.912109   \n",
       "3    28-11-2021  4101.648926  4297.916504  3989.969971  4294.453613   \n",
       "4    29-11-2021  4296.946777  4460.848633  4284.504883  4445.104980   \n",
       "..          ...          ...          ...          ...          ...   \n",
       "361         NaN          NaN          NaN          NaN          NaN   \n",
       "362         NaN          NaN          NaN          NaN          NaN   \n",
       "363         NaN          NaN          NaN          NaN          NaN   \n",
       "364         NaN          NaN          NaN          NaN          NaN   \n",
       "365         NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "       Adj Close        Volume  \n",
       "0    4274.743164  1.870536e+10  \n",
       "1    4030.908936  2.628180e+10  \n",
       "2    4096.912109  1.651569e+10  \n",
       "3    4294.453613  1.595313e+10  \n",
       "4    4445.104980  1.908648e+10  \n",
       "..           ...           ...  \n",
       "361          NaN           NaN  \n",
       "362          NaN           NaN  \n",
       "363          NaN           NaN  \n",
       "364          NaN           NaN  \n",
       "365          NaN           NaN  \n",
       "\n",
       "[366 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_train =  pd.read_csv(\"dataset_dl/ETH-USD-Train.csv\")\n",
    "display(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping NaN rows\n",
    "dataset_train = dataset_train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening price of ETH (in USD)\n",
    "training_set = dataset_train.iloc[:,1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4271.394531]\n",
      " [4522.208984]\n",
      " [4042.999023]\n",
      " [4101.648926]\n",
      " [4296.946777]\n",
      " [4447.768066]\n",
      " [4623.679688]\n",
      " [4586.333008]\n",
      " [4514.355957]\n",
      " [4227.762207]\n",
      " [4119.628906]\n",
      " [4199.      ]\n",
      " [4358.586914]\n",
      " [4311.674316]\n",
      " [4433.024902]\n",
      " [4113.588379]\n",
      " [3909.667725]\n",
      " [4084.811279]\n",
      " [4136.359863]\n",
      " [3782.822754]\n",
      " [3862.251465]\n",
      " [4020.415039]\n",
      " [3959.012451]\n",
      " [3880.291504]\n",
      " [3960.872314]\n",
      " [3923.695801]\n",
      " [3938.463867]\n",
      " [4018.695801]\n",
      " [3981.96167 ]\n",
      " [4111.345215]\n",
      " [4049.781982]\n",
      " [4094.151611]\n",
      " [4064.746338]\n",
      " [4037.538086]\n",
      " [3797.436279]\n",
      " [3632.219727]\n",
      " [3713.430176]\n",
      " [3683.047119]\n",
      " [3769.29834 ]\n",
      " [3829.535645]\n",
      " [3761.361572]\n",
      " [3794.269043]\n",
      " [3549.708984]\n",
      " [3417.837891]\n",
      " [3193.502441]\n",
      " [3091.696289]\n",
      " [3157.570557]\n",
      " [3082.990967]\n",
      " [3238.449951]\n",
      " [3372.10498 ]\n",
      " [3248.648682]\n",
      " [3309.844238]\n",
      " [3330.387207]\n",
      " [3350.947266]\n",
      " [3212.287598]\n",
      " [3163.850342]\n",
      " [3095.271729]\n",
      " [3002.956787]\n",
      " [2561.145264]\n",
      " [2406.924316]\n",
      " [2535.891113]\n",
      " [2440.393555]\n",
      " [2455.579102]\n",
      " [2467.188477]\n",
      " [2421.646973]\n",
      " [2546.590576]\n",
      " [2598.564941]\n",
      " [2603.263428]\n",
      " [2687.898926]\n",
      " [2791.958984]\n",
      " [2682.226074]\n",
      " [2681.057617]\n",
      " [2984.446045]\n",
      " [3014.959717]\n",
      " [3057.422119]\n",
      " [3143.008545]\n",
      " [3121.182617]\n",
      " [3240.113037]\n",
      " [3077.413086]\n",
      " [2927.386475]\n",
      " [2916.789551]\n",
      " [2880.187744]\n",
      " [2933.729004]\n",
      " [3180.446777]\n",
      " [3126.858398]\n",
      " [2884.340576]\n",
      " [2784.872803]\n",
      " [2763.756592]\n",
      " [2627.665527]\n",
      " [2572.898682]\n",
      " [2639.447021]\n",
      " [2588.16626 ]\n",
      " [2598.436279]\n",
      " [2764.989502]\n",
      " [2780.504395]\n",
      " [2621.172119]\n",
      " [2919.775879]\n",
      " [2972.471924]\n",
      " [2950.156738]\n",
      " [2834.987305]\n",
      " [2618.473633]\n",
      " [2664.943604]\n",
      " [2555.297607]\n",
      " [2497.721436]\n",
      " [2577.165283]\n",
      " [2729.116455]\n",
      " [2608.27124 ]\n",
      " [2559.660645]\n",
      " [2573.488037]\n",
      " [2518.486328]\n",
      " [2590.668945]\n",
      " [2620.028564]\n",
      " [2771.964111]\n",
      " [2814.43457 ]\n",
      " [2944.72168 ]\n",
      " [2946.547607]\n",
      " [2860.103271]\n",
      " [2897.77417 ]\n",
      " [2973.14502 ]\n",
      " [3031.060791]\n",
      " [3108.448975]\n",
      " [3106.405273]\n",
      " [3143.795654]\n",
      " [3292.32251 ]\n",
      " [3335.02124 ]\n",
      " [3401.526123]\n",
      " [3385.289307]\n",
      " [3282.576172]\n",
      " [3449.788574]\n",
      " [3444.810547]\n",
      " [3522.36499 ]\n",
      " [3521.239746]\n",
      " [3411.672119]\n",
      " [3172.197266]\n",
      " [3233.272461]\n",
      " [3191.976074]\n",
      " [3261.291504]\n",
      " [3209.576904]\n",
      " [2981.420654]\n",
      " [3029.87793 ]\n",
      " [3117.821777]\n",
      " [3020.134521]\n",
      " [3041.123291]\n",
      " [3061.881836]\n",
      " [2993.483887]\n",
      " [3057.570313]\n",
      " [3103.935059]\n",
      " [3077.829346]\n",
      " [2986.938721]\n",
      " [2964.802246]\n",
      " [2937.347168]\n",
      " [2922.990234]\n",
      " [3008.946289]\n",
      " [2808.645996]\n",
      " [2888.849854]\n",
      " [2936.776611]\n",
      " [2815.533447]\n",
      " [2729.994141]\n",
      " [2827.614014]\n",
      " [2857.152344]\n",
      " [2783.131104]\n",
      " [2940.226563]\n",
      " [2748.931641]\n",
      " [2694.991943]\n",
      " [2636.121826]\n",
      " [2518.508301]\n",
      " [2242.650391]\n",
      " [2342.75415 ]\n",
      " [2072.504639]\n",
      " [1960.122559]\n",
      " [2014.28064 ]\n",
      " [2056.183105]\n",
      " [2145.836914]\n",
      " [2022.882324]\n",
      " [2090.459961]\n",
      " [1916.149536]\n",
      " [2018.000122]\n",
      " [1961.017944]\n",
      " [1974.670654]\n",
      " [2042.344727]\n",
      " [1972.390869]\n",
      " [1978.677002]\n",
      " [1945.033325]\n",
      " [1802.543823]\n",
      " [1724.635986]\n",
      " [1792.184448]\n",
      " [1811.885986]\n",
      " [1996.408081]\n",
      " [1942.050659]\n",
      " [1822.412109]\n",
      " [1834.13501 ]\n",
      " [1775.220825]\n",
      " [1801.81897 ]\n",
      " [1805.635986]\n",
      " [1859.33374 ]\n",
      " [1814.100708]\n",
      " [1793.512817]\n",
      " [1789.689941]\n",
      " [1665.217896]\n",
      " [1530.189697]\n",
      " [1443.835449]\n",
      " [1204.555298]\n",
      " [1211.365967]\n",
      " [1233.603516]\n",
      " [1067.987671]\n",
      " [1086.37793 ]\n",
      " [ 993.400635]\n",
      " [1127.65625 ]\n",
      " [1127.511841]\n",
      " [1125.372925]\n",
      " [1051.329346]\n",
      " [1143.204712]\n",
      " [1226.724731]\n",
      " [1242.987549]\n",
      " [1199.713135]\n",
      " [1193.254028]\n",
      " [1144.524414]\n",
      " [1099.353149]\n",
      " [1068.316772]\n",
      " [1060.121216]\n",
      " [1066.467407]\n",
      " [1073.794312]\n",
      " [1150.509766]\n",
      " [1134.822266]\n",
      " [1186.960938]\n",
      " [1237.580322]\n",
      " [1222.306885]\n",
      " [1216.904419]\n",
      " [1168.139038]\n",
      " [1097.259155]\n",
      " [1038.186646]\n",
      " [1113.515747]\n",
      " [1191.674805]\n",
      " [1232.791626]\n",
      " [1353.205078]\n",
      " [1338.80603 ]\n",
      " [1578.383911]\n",
      " [1542.954346]\n",
      " [1520.374512]\n",
      " [1576.745361]\n",
      " [1536.457397]\n",
      " [1549.222534]\n",
      " [1599.157227]\n",
      " [1445.151123]\n",
      " [1443.726807]\n",
      " [1636.231934]\n",
      " [1725.623901]\n",
      " [1727.06189 ]\n",
      " [1695.884766]\n",
      " [1681.445557]\n",
      " [1634.645874]\n",
      " [1633.05127 ]\n",
      " [1618.886719]\n",
      " [1607.523926]\n",
      " [1732.661133]\n",
      " [1691.777954]\n",
      " [1699.693481]\n",
      " [1776.071289]\n",
      " [1702.906494]\n",
      " [1851.828369]\n",
      " [1880.89917 ]\n",
      " [1957.333984]\n",
      " [1981.782471]\n",
      " [1936.760498]\n",
      " [1902.83313 ]\n",
      " [1877.934326]\n",
      " [1833.715576]\n",
      " [1847.095337]\n",
      " [1612.650635]\n",
      " [1576.543579]\n",
      " [1619.16687 ]\n",
      " [1622.939331]\n",
      " [1662.695435]]\n"
     ]
    }
   ],
   "source": [
    "print(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scalling by doing Normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.90295921]\n",
      " [0.97204879]\n",
      " [0.84004517]\n",
      " [0.85620093]\n",
      " [0.90999785]\n",
      " [0.95154322]\n",
      " [1.        ]\n",
      " [0.98971245]\n",
      " [0.96988558]\n",
      " [0.89094021]\n",
      " [0.86115371]\n",
      " [0.88301734]\n",
      " [0.9269773 ]\n",
      " [0.91405471]\n",
      " [0.94748206]\n",
      " [0.85948978]\n",
      " [0.80331761]\n",
      " [0.85156281]\n",
      " [0.86576243]\n",
      " [0.76837678]\n",
      " [0.79025628]\n",
      " [0.83382417]\n",
      " [0.81691015]\n",
      " [0.79522561]\n",
      " [0.81742247]\n",
      " [0.8071818 ]\n",
      " [0.81124982]\n",
      " [0.83335058]\n",
      " [0.82323177]\n",
      " [0.85887188]\n",
      " [0.84191361]\n",
      " [0.85413571]\n",
      " [0.84603571]\n",
      " [0.8385409 ]\n",
      " [0.77240223]\n",
      " [0.72689153]\n",
      " [0.74926183]\n",
      " [0.74089249]\n",
      " [0.76465133]\n",
      " [0.78124435]\n",
      " [0.76246506]\n",
      " [0.77152978]\n",
      " [0.70416304]\n",
      " [0.66783771]\n",
      " [0.60604206]\n",
      " [0.57799845]\n",
      " [0.59614423]\n",
      " [0.57560047]\n",
      " [0.61842335]\n",
      " [0.65524008]\n",
      " [0.6212327 ]\n",
      " [0.63808968]\n",
      " [0.64374847]\n",
      " [0.64941196]\n",
      " [0.61121664]\n",
      " [0.59787407]\n",
      " [0.57898334]\n",
      " [0.55355418]\n",
      " [0.43185237]\n",
      " [0.38937053]\n",
      " [0.42489584]\n",
      " [0.39859   ]\n",
      " [0.40277302]\n",
      " [0.40597095]\n",
      " [0.39342605]\n",
      " [0.42784313]\n",
      " [0.44216003]\n",
      " [0.44345428]\n",
      " [0.46676805]\n",
      " [0.49543253]\n",
      " [0.46520541]\n",
      " [0.46488354]\n",
      " [0.5484552 ]\n",
      " [0.55686052]\n",
      " [0.56855725]\n",
      " [0.59213297]\n",
      " [0.58612078]\n",
      " [0.61888146]\n",
      " [0.57406398]\n",
      " [0.53273751]\n",
      " [0.52981848]\n",
      " [0.51973611]\n",
      " [0.53448463]\n",
      " [0.60244574]\n",
      " [0.58768423]\n",
      " [0.52088005]\n",
      " [0.49348057]\n",
      " [0.48766388]\n",
      " [0.45017611]\n",
      " [0.43508998]\n",
      " [0.45342145]\n",
      " [0.4392956 ]\n",
      " [0.44212459]\n",
      " [0.4880035 ]\n",
      " [0.49227724]\n",
      " [0.44838743]\n",
      " [0.53064109]\n",
      " [0.54515679]\n",
      " [0.53900983]\n",
      " [0.50728515]\n",
      " [0.4476441 ]\n",
      " [0.46044476]\n",
      " [0.43024157]\n",
      " [0.41438159]\n",
      " [0.43626526]\n",
      " [0.47812187]\n",
      " [0.44483374]\n",
      " [0.43144342]\n",
      " [0.43525233]\n",
      " [0.4201015 ]\n",
      " [0.43998499]\n",
      " [0.44807242]\n",
      " [0.48992473]\n",
      " [0.50162368]\n",
      " [0.53751269]\n",
      " [0.53801566]\n",
      " [0.51420362]\n",
      " [0.52458048]\n",
      " [0.54534221]\n",
      " [0.56129574]\n",
      " [0.58261316]\n",
      " [0.5820502 ]\n",
      " [0.59234979]\n",
      " [0.63326313]\n",
      " [0.64502496]\n",
      " [0.66334446]\n",
      " [0.65887185]\n",
      " [0.63057839]\n",
      " [0.67663888]\n",
      " [0.67526762]\n",
      " [0.69663084]\n",
      " [0.69632088]\n",
      " [0.66613928]\n",
      " [0.60017332]\n",
      " [0.61699715]\n",
      " [0.60562161]\n",
      " [0.6247153 ]\n",
      " [0.61046995]\n",
      " [0.54762182]\n",
      " [0.5609699 ]\n",
      " [0.585195  ]\n",
      " [0.55828598]\n",
      " [0.56406756]\n",
      " [0.56978573]\n",
      " [0.55094477]\n",
      " [0.56859807]\n",
      " [0.58136975]\n",
      " [0.57417865]\n",
      " [0.54914183]\n",
      " [0.5430441 ]\n",
      " [0.5354813 ]\n",
      " [0.53152652]\n",
      " [0.55520406]\n",
      " [0.50002915]\n",
      " [0.52212218]\n",
      " [0.53532413]\n",
      " [0.50192638]\n",
      " [0.47836364]\n",
      " [0.5052541 ]\n",
      " [0.51339076]\n",
      " [0.4930008 ]\n",
      " [0.53627446]\n",
      " [0.48358018]\n",
      " [0.4687219 ]\n",
      " [0.45250549]\n",
      " [0.42010756]\n",
      " [0.34411948]\n",
      " [0.37169416]\n",
      " [0.29725098]\n",
      " [0.26629411]\n",
      " [0.28121254]\n",
      " [0.29275503]\n",
      " [0.31745116]\n",
      " [0.28358197]\n",
      " [0.30219697]\n",
      " [0.25418126]\n",
      " [0.28223712]\n",
      " [0.26654075]\n",
      " [0.27030154]\n",
      " [0.2889431 ]\n",
      " [0.26967355]\n",
      " [0.27140513]\n",
      " [0.26213761]\n",
      " [0.22288733]\n",
      " [0.20142676]\n",
      " [0.22003372]\n",
      " [0.22546073]\n",
      " [0.27628935]\n",
      " [0.26131601]\n",
      " [0.22836026]\n",
      " [0.23158946]\n",
      " [0.21536091]\n",
      " [0.22268766]\n",
      " [0.2237391 ]\n",
      " [0.23853073]\n",
      " [0.2260708 ]\n",
      " [0.22039964]\n",
      " [0.21934658]\n",
      " [0.1850594 ]\n",
      " [0.14786441]\n",
      " [0.12407719]\n",
      " [0.05816486]\n",
      " [0.06004093]\n",
      " [0.06616651]\n",
      " [0.02054581]\n",
      " [0.02561161]\n",
      " [0.        ]\n",
      " [0.03698217]\n",
      " [0.0369424 ]\n",
      " [0.03635321]\n",
      " [0.0159571 ]\n",
      " [0.04126517]\n",
      " [0.06427167]\n",
      " [0.06875144]\n",
      " [0.05683103]\n",
      " [0.0550518 ]\n",
      " [0.04162869]\n",
      " [0.02918578]\n",
      " [0.02063647]\n",
      " [0.01837891]\n",
      " [0.02012704]\n",
      " [0.02214532]\n",
      " [0.04327743]\n",
      " [0.03895613]\n",
      " [0.0533183 ]\n",
      " [0.06726196]\n",
      " [0.06305473]\n",
      " [0.06156656]\n",
      " [0.0481336 ]\n",
      " [0.02860896]\n",
      " [0.0123368 ]\n",
      " [0.03308702]\n",
      " [0.05461678]\n",
      " [0.06594286]\n",
      " [0.09911206]\n",
      " [0.09514569]\n",
      " [0.16114003]\n",
      " [0.15138057]\n",
      " [0.14516071]\n",
      " [0.16068867]\n",
      " [0.14959091]\n",
      " [0.15310721]\n",
      " [0.16686227]\n",
      " [0.1244396 ]\n",
      " [0.12404726]\n",
      " [0.1770749 ]\n",
      " [0.20169889]\n",
      " [0.202095  ]\n",
      " [0.19350692]\n",
      " [0.18952949]\n",
      " [0.176638  ]\n",
      " [0.17619875]\n",
      " [0.17229697]\n",
      " [0.16916697]\n",
      " [0.20363738]\n",
      " [0.19237566]\n",
      " [0.19455608]\n",
      " [0.21559518]\n",
      " [0.19544114]\n",
      " [0.23646329]\n",
      " [0.24447116]\n",
      " [0.26552597]\n",
      " [0.27226057]\n",
      " [0.25985877]\n",
      " [0.25051311]\n",
      " [0.24365446]\n",
      " [0.23147392]\n",
      " [0.23515953]\n",
      " [0.17057917]\n",
      " [0.16063309]\n",
      " [0.17237414]\n",
      " [0.17341331]\n",
      " [0.18436456]]\n",
      "\n",
      "No of Elemets: 273\n"
     ]
    }
   ],
   "source": [
    "print(training_set_scaled)\n",
    "print(f\"\\nNo of Elemets: {len(training_set_scaled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Summary of Feature Scaled Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>273.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.437313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.258616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.219347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.464884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.600173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  273.000000\n",
       "mean     0.437313\n",
       "std      0.258616\n",
       "min      0.000000\n",
       "25%      0.219347\n",
       "50%      0.464884\n",
       "75%      0.600173\n",
       "max      1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Statistical Summary of Feature Scaled Data:\")\n",
    "pd.DataFrame(training_set_scaled).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Data Structure with 60 timestamps (2 months) and 1 output\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(60, len(training_set_scaled)):\n",
    "    X_train.append(training_set_scaled[i-60:i,0])\n",
    "    y_train.append(training_set_scaled[i,0])\n",
    "    \n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90295921, 0.97204879, 0.84004517, 0.85620093, 0.90999785,\n",
       "       0.95154322, 1.        , 0.98971245, 0.96988558, 0.89094021,\n",
       "       0.86115371, 0.88301734, 0.9269773 , 0.91405471, 0.94748206,\n",
       "       0.85948978, 0.80331761, 0.85156281, 0.86576243, 0.76837678,\n",
       "       0.79025628, 0.83382417, 0.81691015, 0.79522561, 0.81742247,\n",
       "       0.8071818 , 0.81124982, 0.83335058, 0.82323177, 0.85887188,\n",
       "       0.84191361, 0.85413571, 0.84603571, 0.8385409 , 0.77240223,\n",
       "       0.72689153, 0.74926183, 0.74089249, 0.76465133, 0.78124435,\n",
       "       0.76246506, 0.77152978, 0.70416304, 0.66783771, 0.60604206,\n",
       "       0.57799845, 0.59614423, 0.57560047, 0.61842335, 0.65524008,\n",
       "       0.6212327 , 0.63808968, 0.64374847, 0.64941196, 0.61121664,\n",
       "       0.59787407, 0.57898334, 0.55355418, 0.43185237, 0.38937053])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213 , 60\n"
     ]
    }
   ],
   "source": [
    "data_size, timestep = X_train.shape\n",
    "print(data_size,\",\", timestep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping Data as (Observations, Timestamp, Indicators)\n",
    "X_train = np.reshape(X_train, newshape=(data_size, timestep, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213, 60, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Keras libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding LSTM layer with dropout regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Layer 1\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(timestep, 1)))\n",
    "model.add(Dropout(0.2))\n",
    "# LSTM Layer 2\n",
    "model.add(LSTM(units=100, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "# LSTM Layer 3\n",
    "model.add(LSTM(units=100, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "# LSTM Layer 4\n",
    "model.add(LSTM(units=100))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommended Optimizer for RNN is 'rmsprop'\n",
    "model.compile(optimizer= 'adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 60, 100)           40800     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 60, 100)           0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 60, 100)           80400     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 60, 100)           0         \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 60, 100)           80400     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 60, 100)           0         \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 282,101\n",
      "Trainable params: 282,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/Fitting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7/7 [==============================] - 6s 46ms/step - loss: 0.0608\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0210\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0152\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0112\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0098\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0107\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0086\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0078\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0072\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0076\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0074\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0082\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0083\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0082\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0077\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0070\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0067\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0070\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0065\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0068\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0062\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0060\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0059\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0058\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0061\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0059\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0064\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0052\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0051\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0055\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0044\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0053\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0044\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0042\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0051\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0047\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0042\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0046\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0042\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0044\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0047\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0039\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0052\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0054\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0045\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0034\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0036\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0041\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0044\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0048\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0036\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0039\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0031\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0031\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0038\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0030\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0034\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0037\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0035\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0036\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0035\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0032\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0032\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0030\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0030\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0031\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0029\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0031\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0026\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0030\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0032\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0032\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0029\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0029\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0031\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0023\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0025\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0027\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0031\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0029\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0028\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0031\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0023\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0025\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0026\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0025\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0028\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0027\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0024\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0026\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0023\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0028\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0025\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0026\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0023\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0024\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0024\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0028\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0031\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0026\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0027\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0027\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0035\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0022\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0023\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0022\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0022\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0025\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0027\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0026\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0023\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0024\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0023\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0023\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0022\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0025\n",
      "Epoch 117/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0023\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0020\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0022\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0020\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0021\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0026\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0021\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0025\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0018\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0018\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0023\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0024\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0026\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0025\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0024\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0025\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0023\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0022\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0022\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0026\n",
      "Epoch 137/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0022\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0027\n",
      "Epoch 139/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0026\n",
      "Epoch 140/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0021\n",
      "Epoch 141/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0022\n",
      "Epoch 142/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0015\n",
      "Epoch 143/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0019\n",
      "Epoch 144/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0019\n",
      "Epoch 145/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0024\n",
      "Epoch 146/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0020\n",
      "Epoch 147/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0020\n",
      "Epoch 148/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0023\n",
      "Epoch 149/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0019\n",
      "Epoch 150/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0020\n",
      "Epoch 151/200\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0020\n",
      "Epoch 152/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0018\n",
      "Epoch 153/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0018\n",
      "Epoch 154/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0021\n",
      "Epoch 155/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0017\n",
      "Epoch 156/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0017\n",
      "Epoch 157/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0018\n",
      "Epoch 158/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0018\n",
      "Epoch 159/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0020\n",
      "Epoch 160/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0018\n",
      "Epoch 161/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0015\n",
      "Epoch 162/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0018\n",
      "Epoch 163/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0016\n",
      "Epoch 164/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0020\n",
      "Epoch 165/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0021\n",
      "Epoch 166/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0020\n",
      "Epoch 167/200\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0018\n",
      "Epoch 168/200\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0017\n",
      "Epoch 169/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0020\n",
      "Epoch 170/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0017\n",
      "Epoch 171/200\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0014\n",
      "Epoch 172/200\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.0019\n",
      "Epoch 173/200\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0016\n",
      "Epoch 174/200\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0015\n",
      "Epoch 175/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0021\n",
      "Epoch 176/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0019\n",
      "Epoch 177/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0020\n",
      "Epoch 178/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0016\n",
      "Epoch 179/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0017\n",
      "Epoch 180/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0018\n",
      "Epoch 181/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0022\n",
      "Epoch 182/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0019\n",
      "Epoch 183/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0017\n",
      "Epoch 184/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0017\n",
      "Epoch 185/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0016\n",
      "Epoch 186/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0018\n",
      "Epoch 187/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0016\n",
      "Epoch 188/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0015\n",
      "Epoch 189/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0019\n",
      "Epoch 190/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0017\n",
      "Epoch 191/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0016\n",
      "Epoch 192/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0018\n",
      "Epoch 193/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0018\n",
      "Epoch 194/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0014\n",
      "Epoch 195/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0019\n",
      "Epoch 196/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0019\n",
      "Epoch 197/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0017\n",
      "Epoch 198/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0015\n",
      "Epoch 199/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0016\n",
      "Epoch 200/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0016\n"
     ]
    }
   ],
   "source": [
    "r = model.fit(X_train, y_train, epochs=200, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e85556cd639849d6c1361db0a433433fe588bb9e07514b044682fe76c87df726"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
